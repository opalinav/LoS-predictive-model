{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.read_csv('Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('data_v5.csv')\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates and Scrambling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate rows\n",
    "df=df.drop_duplicates(keep='first')\n",
    "\n",
    "#scrambles data randomnly\n",
    "df = df.sample(frac=1, random_state=4).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be equal to number of rows, \n",
    "len(df['ADMIT_NUMBER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(['ADMIT_NUMBER'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capping LoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['LENGTH_OF_STAY_DAYS']<=14])*100/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['LENGTH_OF_STAY_DAYS']==0])*100/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = df.boxplot(column=['LENGTH_OF_STAY_DAYS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['LENGTH_OF_STAY_DAYS']<=14]\n",
    "boxplot = df.boxplot(column=['LENGTH_OF_STAY_DAYS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unique identifiers\n",
    "\n",
    "df=df.drop(columns='UR_NUMBER',axis=1)\n",
    "df=df.drop(columns='PATIENT_NUMBER',axis=1)\n",
    "df=df.drop(columns='ANE_NUMBER',axis=1)\n",
    "df=df.drop(columns='ADMIT_NUMBER',axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AGE_ON_ADMISSION'][df['AGE_ON_ADMISSION']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AGE_ON_ADMISSION'][df['AGE_ON_ADMISSION']<0]=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time and date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import calendar\n",
    "\n",
    "df['ADMISSION_DATE']=pd.to_datetime(df['ADMISSION_DATE'], format =\"%d/%m/%Y\")\n",
    "df['ADMISSION_TIME']=pd.to_datetime(df['ADMISSION_TIME'])\n",
    "\n",
    "df['DAY_OF_WEEK']=df['ADMISSION_DATE'].dt.day_name()\n",
    "df['DAY_OF_WEEK']=df['DAY_OF_WEEK'].apply(str)\n",
    "\n",
    "df['ADMISSION_YEAR']=df['ADMISSION_DATE'].dt.year\n",
    "df['ADMISSION_YEAR']=df['ADMISSION_YEAR'].apply(str)\n",
    "\n",
    "df['ADMISSION_MONTH']=df['ADMISSION_DATE'].dt.month\n",
    "df['ADMISSION_MONTH']=df['ADMISSION_MONTH'].apply(str)\n",
    "\n",
    "df['ADMISSION_HOUR']=df['ADMISSION_TIME'].dt.hour\n",
    "df['ADMISSION_HOUR']=df['ADMISSION_HOUR'].apply(str)\n",
    "\n",
    "df[\"IsWeekend\"] = df['ADMISSION_DATE'].dt.weekday >=5\n",
    "df['IsWeekend']=df['IsWeekend'].apply(str)\n",
    "\n",
    "from govuk_bank_holidays.bank_holidays import BankHolidays\n",
    "\n",
    "bank_holidays = BankHolidays()\n",
    " \n",
    "df['IS_HOLIDAY']=df['ADMISSION_DATE'].isin(bank_holidays._get_known_holiday_date_set())\n",
    "df['IS_HOLIDAY']=df['IS_HOLIDAY'].apply(str)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IS_HOLIDAY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if any times are negative\n",
    "\n",
    "print(len(df['TRIAGE_TO_SEEN_WAIT'][df['TRIAGE_TO_SEEN_WAIT']<0]))\n",
    "print(len(df['ARRIVAL_TO_TREATMENT_WAIT'][df['ARRIVAL_TO_TREATMENT_WAIT']<0]))\n",
    "print(len(df['ARRIVAL_TO_CONCLUSION_WAIT'][df['ARRIVAL_TO_CONCLUSION_WAIT']<0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lotsof entries have zero, so cannot replace negative with zero\n",
    "df['TRIAGE_TO_SEEN_WAIT'][df['TRIAGE_TO_SEEN_WAIT']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace negative entries with None\n",
    "\n",
    "df['TRIAGE_TO_SEEN_WAIT'][df['TRIAGE_TO_SEEN_WAIT']<0]=None\n",
    "df['ARRIVAL_TO_TREATMENT_WAIT'][df['ARRIVAL_TO_TREATMENT_WAIT']<0]=None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['ADMISSION_DATE'], axis=1)\n",
    "df=df.drop(['ADMISSION_TIME'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Change LoS\n",
    "df['READMITTED']=df['DAYS_SINCE_LAST_DISCHARGE']<=30\n",
    "df['READMITTED']=df['READMITTED'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['READMITTED','DAYS_SINCE_LAST_DISCHARGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['DAYS_SINCE_LAST_DISCHARGE'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_num = df.select_dtypes(include=['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.subplots(figsize=(12, 21))\n",
    "# i=0\n",
    "# for feature in explore_num.columns:\n",
    "#     if feature not in ['LENGTH_OF_STAY_DAYS']:\n",
    "#         i+=1\n",
    "#         plt.subplot(13, 3, i)\n",
    "#         sns.distplot(df[feature])\n",
    "#         plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.subplots(figsize=(12, 21))\n",
    "# i=0\n",
    "# for feature in explore_num.columns:\n",
    "#     if feature not in ['LENGTH_OF_STAY_DAYS']:\n",
    "#         i+=1\n",
    "#         plt.subplot(13, 3, i)\n",
    "#         sns.scatterplot(df[feature], df['LENGTH_OF_STAY_DAYS'])\n",
    "#         plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce and Combine Ward Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADMIT_WARD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADMIT_WARD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make hdu, picu, and burns unit their own categories, make all the wards not include color\n",
    "df.loc[df['ADMIT_WARD'].str.contains('PICU'), 'ADMIT_WARD'] = 'PICU'\n",
    "df.loc[df['ADMIT_WARD'].str.contains('HDU'), 'ADMIT_WARD'] = 'HDU'\n",
    "df.loc[df['ADMIT_WARD'].str.contains('Burns'), 'ADMIT_WARD'] = 'Burn Unit '\n",
    "\n",
    "#exceptions, 1c is neonatal\n",
    "df.loc[df['ADMIT_WARD'].str.contains('1C Yellow'), 'ADMIT_WARD'] = 'neonatal'\n",
    "\n",
    "#differentiate between ward with ensuite room vs without (orange has no ensuite, yellow,green, and blue are ensuite)\n",
    "#df.loc[df['ADMIT_WARD'].str.contains('Orange'), 'ADMIT_WARD'] = df['ADMIT_WARD'].str[0:]\n",
    "\n",
    "df.loc[df['ADMIT_WARD'].str.contains('Ward'), 'ADMIT_WARD'] = df['ADMIT_WARD'].str[0:7]\n",
    "\n",
    "\n",
    "df['ADMIT_WARD'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['ADMIT_WARD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ETHNICITY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ETHNICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df\n",
    "#X=X.drop(columns='LENGTH_OF_STAY_DAYS',axis=1). dont drop yet because needed for heat map\n",
    "Y=df.LENGTH_OF_STAY_DAYS\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_num = X_train.select_dtypes(include=['int64', 'float64'])\n",
    "xtest_num= X_test.select_dtypes(include=['int64', 'float64'])\n",
    "xtrain_cat = X_train.select_dtypes(include=['object'])\n",
    "xtest_cat = X_test.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_cat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Null Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(data):\n",
    "        return pd.DataFrame({\"Data Type\":data.dtypes, \"Unique Count\":data.apply(lambda x: x.nunique(),axis=0), \n",
    "                         \"Null Count\": data.isnull().sum() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in xtrain_num.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in xtrain_cat.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(xtrain_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(xtrain_num)[analysis(xtrain_num)[\"Null Count\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cannot fill null with 0, since 0 is already filled, instead fill with -1\n",
    "\n",
    "#xtrain_num['DAYS_SINCE_LAST_DISCHARGE']=xtrain_num['DAYS_SINCE_LAST_DISCHARGE'].fillna(-1)\n",
    "###possibly make this categorical, has been readmitted (30 days) yes or no\n",
    "xtrain_num['Total_LOS_(within_last_12mth)']=xtrain_num['Total_LOS_(within_last_12mth)'].fillna(0)\n",
    "analysis(xtrain_num)[analysis(xtrain_num)[\"Null Count\"]>0]\n",
    "####cumulative, fill 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtrain_num = xtrain_num.fillna(xtrain_num.median())\n",
    "analysis(xtrain_num)[analysis(xtrain_num)[\"Null Count\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_num = xtest_num.fillna(xtrain_num.median())\n",
    "analysis(xtest_num)[analysis(xtest_num)[\"Null Count\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(xtrain_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_cat['AEOBS'].fillna('N', inplace = True)\n",
    "xtest_cat['AEOBS'].fillna('N', inplace = True)\n",
    "analysis(xtrain_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "impute_cat_features = list(xtrain_cat.columns)\n",
    "\n",
    "\n",
    "for feat in impute_cat_features:\n",
    "    xtrain_cat[feat].fillna(value='NA_' + feat, inplace = True)\n",
    "    xtest_cat[feat].fillna(value='NA_' + feat, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(xtrain_cat)[analysis(xtrain_cat)[\"Null Count\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_cat['ETHNICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with Outliers (only applies to numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_num[xtrain_num['RespiratoryRate']<=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_num['RespiratoryRate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(xtrain_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats.mstats import winsorize\n",
    "\n",
    "#DID NOT INCLUDE: AGE_ON, _ADMISSION, LENGTH_OF_STAY_DAYS, IMD_Decile_DOOGAl, 'IMD_QUINTILE_DOOGAL','Index_of_Multiple_Deprivation_Decile', 'Income_Decile',\n",
    "#        'Employment_Decile', 'Education_and_Skills_Decile', 'IDACI_Decile',\n",
    "#        'TRIAGE_PRIORITY'\n",
    "\n",
    "from feature_engine.outliers import Winsorizer\n",
    "capper = Winsorizer(capping_method='iqr', tail='both', fold=2, variables=['PulseRate', 'RespiratoryRate', 'SP02',\n",
    "       'Temperature','Distance_from_Home_Address', 'Population',\n",
    "       'Households','IMD_DOOGAL', 'Distance to station', 'Average Income','Index_of_Multiple_Deprivation_Rank',\n",
    "        'ARRIVAL_TO_TREATMENT_WAIT', 'TRIAGE_TO_SEEN_WAIT',\n",
    "       'ARRIVAL_TO_CONCLUSION_WAIT',\n",
    "       'Total_LOS_(within_last_12mth)', 'Admits_last_12mth'])\n",
    "\n",
    "# fit the capper\n",
    "capper.fit(xtrain_num)\n",
    "\n",
    "# transform the data\n",
    "xtrain_num= capper.transform(xtrain_num)\n",
    "xtest_num= capper.transform(xtest_num)\n",
    "capper.right_tail_caps_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capper.left_tail_caps_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "xtrain_num.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rare labels/categories (only applies to categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use rare label encoder\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "#excluding 'ADMISSION_YEAR', \n",
    "\n",
    "#using to not overfit, want to fit general pattern, gauge effect of different categories on LoS\n",
    "###change to 1%\n",
    "encoder = RareLabelEncoder(tol=0.02, n_categories=2, replace_with='Rare')\n",
    "\n",
    "# fit the encoder\n",
    "encoder.fit(xtrain_cat)\n",
    "\n",
    "# transform the data\n",
    "xtrain_cat = encoder.transform(xtrain_cat)\n",
    "xtest_cat = encoder.transform(xtest_cat)\n",
    "\n",
    "encoder.encoder_dict_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_cat['ETHNICITY'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as before just replaced black with rare\n",
    "\n",
    "xtrain_cat['ETHNICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(xtrain_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "\n",
    "encoder = OrdinalEncoder(encoding_method='ordered', variables=['TriageCat'])\n",
    "\n",
    "# fit the encoder\n",
    "encoder.fit(xtrain_cat, Y_train)\n",
    "\n",
    "# transform the data\n",
    "xtrain_cat= encoder.transform(xtrain_cat)\n",
    "xtest_cat= encoder.transform(xtest_cat)\n",
    "\n",
    "encoder = OrdinalEncoder(encoding_method='arbitrary', variables=['ADMIT_SOURCE', 'ADMIT_WARD', 'ADMIT_SPECIALTY', 'ADMIT_CONSULTANT',\n",
    "       'AVPU', 'Visit_Reason', 'AEOBS', 'PRIMARY_DIAG_CODE',\n",
    "       'PATIENT_POSTCODE', 'ARRIVAL_TRANSPORT', 'GENDER', 'ETHNICITY',\n",
    "       'SAFE_GUARDING', 'Patient_Has_Learning_Disability',\n",
    "       'Patient_is_Looked_After_Child', 'REFER_SOURCE', 'County', 'District',\n",
    "       'Ward', 'Country', 'Constituency', 'Rural/urban', 'Region',\n",
    "       'Middle layer super output area', 'Nearest station',\n",
    "       'DOCTOR_ALLOCATED_CODE', 'ReferralSource',\n",
    "       'ExaminationDoctor', 'AccomodationStatus', 'SITUATION_CODE', 'DIABETES',\n",
    "       'DAY_OF_WEEK', 'ADMISSION_YEAR', 'ADMISSION_MONTH', 'ADMISSION_HOUR',\n",
    "       'IsWeekend', 'IS_HOLIDAY', 'READMITTED'])\n",
    "\n",
    "# fit the encoder\n",
    "encoder.fit(xtrain_cat, Y_train)\n",
    "\n",
    "# transform the data\n",
    "xtrain_cat= encoder.transform(xtrain_cat)\n",
    "xtest_cat= encoder.transform(xtest_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_cat.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine categorical and Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.concat([xtrain_num,xtrain_cat], axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.concat([xtest_num,xtest_cat], axis=1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(xtrain_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "lgbm=LGBMRegressor(random_state=4)\n",
    "\n",
    "tr = SmartCorrelatedSelection(\n",
    "    method=\"pearson\",\n",
    "    threshold=0.85,\n",
    "    selection_method=\"model_performance\",\n",
    "    estimator=lgbm,\n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "tr.fit(X_train, Y_train)\n",
    "X_train=tr.transform(X_train)\n",
    "X_test=tr.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.correlated_feature_sets_)\n",
    "print(tr.features_to_drop_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection Heatmap\n",
    "corr = X_train.corr()\n",
    "cor_target = abs(corr[\"LENGTH_OF_STAY_DAYS\"])\n",
    "#Selecting highly correlated features\n",
    "heatmap_features = cor_target[cor_target>0.001]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.heatmap(corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##features from Heat Map\n",
    "heatmap_features.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Drop Target Feature after HeatMap\n",
    "X_train=X_train.drop(columns='LENGTH_OF_STAY_DAYS',axis=1)\n",
    "\n",
    "X_test=X_test.drop(columns='LENGTH_OF_STAY_DAYS',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from feature_engine.selection import RecursiveFeatureAddition\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=10,max_depth=5,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#linear_model = LinearRegression()\n",
    "tr = RecursiveFeatureAddition(estimator=regressor, scoring=\"neg_mean_absolute_error\", cv=5, threshold=.00001)\n",
    "\n",
    "rfa=tr.fit_transform(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=len(rfa.columns)\n",
    "rfa_features=list(tr.feature_importances_.index[0:num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfa_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# regressor = RandomForestRegressor(n_estimators=10, max_depth=5,random_state=4)\n",
    "\n",
    "# #===========================================================================\n",
    "# # perform a scikit-learn Recursive Feature Elimination (RFE)\n",
    "# #===========================================================================\n",
    "# from sklearn.feature_selection import RFE\n",
    "# # here we want only one final feature, we do this to produce a ranking\n",
    "# ##see if there is argument threshold, otherwise use RFA that data team uses\n",
    "# rfe = RFE(regressor)\n",
    "# rfe.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from operator import itemgetter\n",
    "# features = X_train.columns.to_list()\n",
    "# RFR_feat_sorted=[]\n",
    "# for x, y in (sorted(zip(rfe.ranking_ , features), key=itemgetter(0))):\n",
    "#     RFR_feat_sorted.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFR_feat_sorted[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##%%timeit\n",
    "#Feature Selection, Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "##need to look into parameters of cross-validation, max_iter\n",
    "\n",
    "\n",
    "lasso = LassoCV(cv=10, random_state=4, max_iter=2000).fit(X_train, Y_train)\n",
    "importance = np.abs(lasso.coef_)\n",
    "feature_names = np.array(X_train.columns.values.tolist())\n",
    "\n",
    "lasso_features = np.array(X_train.columns)[importance > 0.0000]\n",
    "list(lasso_features)\n",
    "\n",
    "\n",
    "#before scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2, f_regression\n",
    "from numpy import array \n",
    "\n",
    "###cv\n",
    "select = SelectKBest(score_func=f_regression, k=15)\n",
    "z=select.fit_transform(X_train, Y_train) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = select.get_support()\n",
    "features = array(X_train.columns)\n",
    " \n",
    "\n",
    " \n",
    "print(\"Selected best 25:\")\n",
    "#print(features[filter])\n",
    "k_best_feat=features[filter]\n",
    "print(k_best_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_features=list(lasso_features)\n",
    "k_best_feat=list(k_best_feat)\n",
    "rfa_features=list(rfa_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lasso:', lasso_features)\n",
    "print('k_best:', k_best_feat)\n",
    "print('rfa:', rfa_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_lasso=['PulseRate', 'Distance_from_Home_Address', 'IMD_DOOGAL', 'Average Income', \n",
    "           'Index_of_Multiple_Deprivation_Rank', 'TRIAGE_TO_SEEN_WAIT', 'ARRIVAL_TO_CONCLUSION_WAIT', 'ADMIT_WARD']\n",
    "\n",
    "old_k=['AGE_ON_ADMISSION', 'PulseRate', 'RespiratoryRate', 'SP02', 'Distance_from_Home_Address', \n",
    "        'TRIAGE_PRIORITY', 'ARRIVAL_TO_CONCLUSION_WAIT', 'Total_LOS_(within_last_12mth)', \n",
    "        'Admits_last_12mth', 'ADMIT_WARD', 'ADMIT_SPECIALTY', 'ADMIT_CONSULTANT', 'AVPU', \n",
    "        'Visit_Reason', 'AEOBS', 'PRIMARY_DIAG_CODE', 'SAFE_GUARDING', 'Patient_Has_Learning_Disability', \n",
    "        'County', 'District', 'Constituency', 'Rural/urban', 'Region', 'TriageCat', 'READMITTED']\n",
    "\n",
    "old_rfa=['ADMIT_SPECIALTY', 'AEOBS', 'ADMIT_WARD', 'Total_LOS_(within_last_12mth)', \n",
    "         'SP02', 'TRIAGE_PRIORITY', 'ARRIVAL_TO_CONCLUSION_WAIT', 'PRIMARY_DIAG_CODE', \n",
    "         'ExaminationDoctor', 'ADMISSION_HOUR', 'PulseRate', 'Patient_Has_Learning_Disability', \n",
    "         'AGE_ON_ADMISSION', 'District']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rfa_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "column_names=X_train.columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "X_train=pd.DataFrame(X_train,columns=column_names)\n",
    "X_test=pd.DataFrame(X_test,columns=column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def intersection(ls1,ls2,ls3):\n",
    "#     s1=set(ls1)\n",
    "#     s2=set(ls2)\n",
    "#     s3=set(ls3)\n",
    "#     new=s1.intersection(s2,s3)\n",
    "#     return list(new)\n",
    "# inter=intersection(lasso_features,rfa_features, k_best_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "lasso_train=X_train[lasso_features]\n",
    "    \n",
    "lasso_test=X_test[lasso_features]   \n",
    "    \n",
    "rfa_train=X_train[rfa_features]\n",
    "\n",
    "rfa_test=X_test[rfa_features]\n",
    "\n",
    "kbest_train=X_train[k_best_feat]\n",
    "\n",
    "kbest_test=X_test[k_best_feat]\n",
    "\n",
    "# inter_train=X_train[inter]\n",
    "# inter_test=X_train[inter]\n",
    "\n",
    "unique=list(set(lasso_features+k_best_feat+rfa_features))\n",
    "unique_train=X_train[unique]\n",
    "unique_test=X_test[unique]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_to_feat={'All Feat': (X_train,X_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=[['Linear Regression', 'Random Forest', 'Decision Tree', 'SVR', 'LGBM', 'CatBoost'], ['features','CV MAE','MAE','MSE', 'RMSE', 'R^2']]\n",
    "index=pd.MultiIndex.from_product(indices, names=['Models', 'Metrics'])\n",
    "###\n",
    "metric=pd.DataFrame(index=index, columns=['Lasso Feat', 'RFA Feat', 'K_best Feat','Union','All Feat'])\n",
    "#metric.set_index([pd.Index(['Linear Regression', 'Random Forest']), metric.index])\n",
    "          #d.DataFrame(metric,index=['Linear Regression', 'Random Forest'])\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import tree\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "linear=('Linear Regression',LinearRegression())\n",
    "tree=('Decision Tree', tree.DecisionTreeRegressor(criterion='absolute_error',random_state=4))\n",
    "random=('Random Forest', RandomForestRegressor(n_estimators=50,max_depth=5, random_state=4, criterion='absolute_error'))\n",
    "svr=('SVR', SVR())\n",
    "\n",
    "lgbm=('LGBM', LGBMRegressor(random_state=4))\n",
    "cat=('CatBoost',CatBoostRegressor(random_state=4, loss_function='MAE'))\n",
    "\n",
    "algorithms=[linear,tree,lgbm,cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import mean\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "for alg in algorithms:\n",
    "    #cross validation:\n",
    "    \n",
    "\n",
    "    for method in method_to_feat:\n",
    "        x=method_to_feat[method]\n",
    "        X_train=x[0]\n",
    "        X_test=x[1]\n",
    "\n",
    "\n",
    "        reg = alg[1]\n",
    "        alg_str=alg[0]\n",
    "        \n",
    "        cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=4)\n",
    "        n_scores = cross_val_score(reg, X_train, Y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        metric.loc[(alg_str,'CV MAE')][method] = mean(n_scores)\n",
    "\n",
    "        # Fitting training data\n",
    "        reg = reg.fit(X_train, Y_train)\n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        #mean absolute error\n",
    "        mae=metrics.mean_absolute_error(Y_test, y_pred)\n",
    "        #mean squared error\n",
    "        mse=metrics.mean_squared_error(Y_test, y_pred)\n",
    "        #root mean squared error\n",
    "        rmse=np.sqrt(metrics.mean_squared_error(Y_test, y_pred))\n",
    "        #r-squared\n",
    "        r_square=reg.score(X_test,Y_test)\n",
    "\n",
    "        metric.loc[(alg_str,'features')][method] = len(X_train.columns)\n",
    "        metric.loc[(alg_str,'MAE')][method] = mae\n",
    "        metric.loc[(alg_str,'MSE')][method] = mse\n",
    "        metric.loc[(alg_str,'RMSE')][method] = rmse\n",
    "        metric.loc[(alg_str,'R^2')][method] = r_square\n",
    "        \n",
    "        print(metric)\n",
    "\n",
    "\n",
    "\n",
    "metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
